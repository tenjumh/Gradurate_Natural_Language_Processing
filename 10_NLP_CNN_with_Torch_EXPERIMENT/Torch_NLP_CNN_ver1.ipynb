{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Torch_NLP_CNN_ver1.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6PGx_OGP1Qx",
        "colab_type": "code",
        "outputId": "2c42a02a-c748-477d-f96e-75867239ce97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "!pip install PyKomoran"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting PyKomoran\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/b0/ce6a46f311651ed64c39beb1cfe1c39a9906521139ace45430d08c489b62/PyKomoran-0.1.5-py3-none-any.whl (7.9MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9MB 2.4MB/s \n",
            "\u001b[?25hCollecting py4j==0.10.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/de/2d314a921ef4c20b283e1de94e0780273678caac901564df06b948e4ba9b/py4j-0.10.8.1-py2.py3-none-any.whl (196kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 28.6MB/s \n",
            "\u001b[?25hInstalling collected packages: py4j, PyKomoran\n",
            "Successfully installed PyKomoran-0.1.5 py4j-0.10.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcZcMDsSP8Q8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "from PyKomoran import *\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, fbeta_score\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNGeTT_jP-_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_seed():\n",
        "  random.seed(777)\n",
        "  np.random.seed(777)\n",
        "  torch.manual_seed(777)\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(777)\n",
        "\n",
        "set_seed()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOIGOeuRP_wn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train Data 와 Test Data 의 발화를 형태소 분석\n",
        "komoran = Komoran(\"EXP\")\n",
        "\n",
        "with open('SpeechAct_tr.json', 'r', encoding='utf-8') as read_file:\n",
        "    data_tr = json.load(read_file)\n",
        "with open('SpeechAct_te.json', 'r', encoding='utf-8') as read_file:\n",
        "    data_te = json.load(read_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz1j_trtQCI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "docs_tr = []\n",
        "words_tr = []\n",
        "voca_tr = []\n",
        "for key in data_tr.keys():\n",
        "    for message in data_tr[key]:\n",
        "        komoran_text = komoran.get_plain_text(message[1])\n",
        "        komoran_text = komoran_text.split(' ')\n",
        "        for voc in komoran_text:\n",
        "          voca_tr.append(voc)\n",
        "        #print(komoran_text)\n",
        "        words_tr.append(komoran_text)\n",
        "    docs_tr.append(words_tr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4wBV-XAQDiu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "docs_te = []\n",
        "words_te = []\n",
        "for key in data_te.keys():\n",
        "    for message in data_te[key]:\n",
        "        komoran_text = komoran.get_plain_text(message[1])\n",
        "        komoran_text = komoran_text.split(' ')\n",
        "        words_te.append(komoran_text)\n",
        "    docs_te.append(words_te)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvFzBvuvQFKZ",
        "colab_type": "code",
        "outputId": "3b045bb3-8a33-4f33-8032-6b8a6e05bea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(len(docs_tr), len(docs_te))\n",
        "print(len(words_tr), len(words_te))\n",
        "print(len(voca_tr))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "260 40\n",
            "5825 6671\n",
            "48472\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peoJyYGzQGe7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 형태소 분석한 Train Data 의 발화를 이용하여 word2idx 구축\n",
        "words_dic = sorted(set(voca_tr))\n",
        "word2index = {}\n",
        "word2index['<PAD>'] = 0\n",
        "word2index['<UKN>'] = 1\n",
        "for idx, word in enumerate(words_dic):\n",
        "  word2index[word] = idx + 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXqIXWBFQIkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train data label -> label2idx구축\n",
        "label2idx = {'opening' : 0, 'request' : 1, 'wh-question' : 2, 'yn-question' : 3,\n",
        "             'inform' : 4, 'affirm' : 5, 'ack' : 6, 'expressive' : 7}\n",
        "\n",
        "def labellist(path):\n",
        "  with open(path, 'r', encoding='utf-8') as read_file:\n",
        "    data = json.load(read_file)\n",
        "\n",
        "  label_list = []\n",
        "  for idx, labels in enumerate(data.values()):\n",
        "    for label in labels:\n",
        "      label_list.append(label2idx[label[2]])\n",
        "  return label_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urwBkfkB1PtD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_list_tr = labellist('SpeechAct_tr.json')\n",
        "label_list_te = labellist('SpeechAct_te.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Icrw7BxzQKS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# emd = nn.Embedding(num_embeddings = len(word2index) ,embedding_dim = 128)\n",
        "word_list_tr = []\n",
        "for key in data_tr:\n",
        "  if 0 < len(data_tr[key]):\n",
        "    sentence_list = [i[1] for i in data_tr[key]]\n",
        "    for sentence in sentence_list:\n",
        "      index_word = []\n",
        "      if sentence:\n",
        "        o_word = komoran.get_plain_text(sentence)\n",
        "        for word in o_word.split(' '):\n",
        "          index_word.append(word2index[word])      \n",
        "      word_list_tr.append(index_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2L6J3b1xDM2p",
        "colab_type": "code",
        "outputId": "9b12fccc-5ad7-4dcc-9967-b6cb978df845",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "word2index.keys()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['<PAD>', '<UKN>', '!/SF', \"'/SS\", '(/SS', ',/SP', '-/SS', './SF', '0/SO', '000/SN', '08/SN', '1/SN', '10/SN', '10분/NNP', '10월', '10일/NNP', '11/SN', '11월', '11일/NNP', '12/SN', '12월', '12일/NNP', '13/SN', '13일/NNP', '14/SN', '14일/NNP', '15/SN', '15일/NNP', '16/SN', '16일/NNP', '17일/NNP', '18/SN', '18일/NNP', '19/SN', '19일/NNP', '1일/NNP', '2/SN', '20/SN', '20일/NNP', '22일/NNP', '23/SN', '23일/NNP', '24/SN', '24일/NNP', '25일/NNP', '26일/NNP', '27/SN', '27일/NNP', '28/SN', '28일/NNP', '29일/NNP', '2시/NNP', '2일/NNP', '3/SN', '30/SN', '30일/NNP', '31/SN', '33/SN', '3월', '3일/NNP', '4/SN', '46/SN', '4월', '4월/NNP', '4일/NNP', '5/SN', '50/SN', '5월', '5일/NNP', '6/SN', '60/SN', '6월', '6일/NNP', '7/SN', '7월', '7월/NNP', '7일/NNP', '8/SN', '8월', '8일/NNP', '9/SN', '9월', '9월/NNP', '9일/NNP', '?/SF', 'CGV/SL', 'MMC/SL', 'ㄴ/ETM', 'ㄴ/JX', 'ㄴ가/EF', 'ㄴ가요/EF', 'ㄴ다/EF', 'ㄴ다고/EC', 'ㄴ다고/EF', 'ㄴ단다/EF', 'ㄴ데/EC', 'ㄴ데/EF', 'ㄴ데요/EF', 'ㄴ지/EC', 'ㄹ/ETM', 'ㄹ건데/EF', 'ㄹ걸/EC', 'ㄹ게/EC', 'ㄹ게/EF', 'ㄹ게요/EF', 'ㄹ까/EF', 'ㄹ까요/EF', 'ㄹ래/EF', 'ㄹ려고/EC', 'ㄹ려는/ETM', 'ㄹ지/EC', 'ㄹ테니까/EC', 'ㅁ/ETN', 'ㅂ니다/EF', '가/JKS', '가/VV', '가/VX', '가깝/VA', '가능/XR', '가르치/VV', '가방/NNP', '가시/VV', '가야/NNP', '가이즈/NNP', '가장/MAG', '가져가/VV', '가족/NNG', '가지/VV', '가지/VX', '각/MM', '간/NNB', '간다/NNP', '간부/NNG', '간지/NNP', '갈/VV', '갈래/NNG', '강릉시/NNP', '강변/NNG', '강원도/NNP', '강하/VA', '갖/VV', '같/VA', '같이/MAG', '개/NNB', '개봉/NNG', '걔/NP', '거/NNB', '거기/NP', '거든/EC', '거든/EF', '거래처/NNG', '거실/NNP', '거지/NNG', '건/NNB', '건국대학교/NNP', '건데/EC', '걷/VV', '걸/VV', '검/NNG', '검색/NNG', '검색/NNP', '검진/NNG', '것/NNB', '게/EC', '게/EF', '게/NNG', '겠/EP', '결혼기념일/NNP', '결혼식/NNG', '결혼식/NNP', '겹치/VV', '경/XSN', '경기/NNG', '경기/NNP', '경옥이/NNP', '경포대/NNP', '경포해수욕장/NNP', '계시/VV', '계열/NNG', '계획/NNG', '고/EC', '고/EF', '고/XPN', '고등학교/NNG', '고등학교/NNP', '고르/VV', '고마워요/NNP', '고맙/VA', '고모/NNG', '고생/NNG', '고치/VV', '골프/NNP', '골프장/NNG', '곳/NNG', '공개/NNG', '공연/NNG', '공원/NNP', '공주/NNP', '과/JC', '과/JKB', '과외/NNP', '과제/NNG', '과천/NNP', '관람/NNG', '관리/NNG', '광장/NNP', '괜찮/VA', '교보문고/NNP', '교시/NNB', '교시/NNG', '교육/NNG', '교촌/NNP', '교회/NNG', '구나/EC', '구나/EF', '구름/NNP', '국희/NNP', '군/NNG', '군요/EF', '궁금/XR', '권/NNB', '그/MM', '그/NP', '그것/NP', '그곳/NP', '그날/NNG', '그냥/MAG', '그때/NNG', '그래/IC', '그래서/MAJ', '그러/VV', '그러면/MAJ', '그럼/MAJ', '그렇/VA', '그리고/MAJ', '그만/MAG', '극장/NNG', '극장/NNP', '근/NNB', '근데/MAJ', '근처/NNG', '금/NNG', '금액/NNG', '금요일/NNP', '금주/NNP', '기/ETN', '기간/NNG', '기간/NNP', '기념/NNG', '기념일/NNP', '기다리/VV', '기록/NNG', '기말/NNG', '기말고사/NNP', '기분/NNG', '기분/NNP', '기상/NNP', '기성/NNG', '기온/NNP', '기와/NNP', '긴급회의/NNG', '김/NNP', '까지/JX', '까지/VV', '깨우/VV', '꺼/NNB', '께/JKB', '께서/JKS', '꼭/MAG', '끊/VV', '끝나/VV', '끝내/VV', '끼/VV', '끼리/XSN', '나/EC', '나/EF', '나/NP', '나/VV', '나가/VV', '나들/NNP', '나들이/NNG', '나오/VV', '나요/EF', '낙산/NNP', '낙산해수욕장/NNP', '난', '날/NNG', '날/NNP', '날로/MAG', '날씨/NNG', '날씨/NNP', '날짜/NNG', '날짜/NNP', '남/VV', '낮/NNG', '내/NNB', '내/NP', '내려가/VV', '내야/NNP', '내용/NNG', '내일/NNG', '내일/NNP', '내일로/NNP', '내주/VV', '냐/EF', '냐면/EC', '너/NP', '너무/MAG', '넣/VV', '네/EC', '네/EF', '네/IC', '네/MM', '네/XSN', '네요/EF', '넥스투어가/NA', '넥타이/NNP', '놀/VV', '농구/NNP', '놓/VV', '놓/VX', '누구/NP', '누나/NNG', '는/ETM', '는/JX', '는데/EC', '는데/EF', '는데요/EF', '는지/EC', '는지/EF', '늦/VA', '늦추/VV', '니/EF', '니/NP', '니까/EC', '니깐/EC', '님/XSN', '다/EC', '다/EF', '다/JX', '다/MAG', '다/NNG', '다고/EC', '다녀오/VV', '다니/VV', '다른/MM', '다면/EC', '다시/MAG', '다음/NNG', '다음/NNP', '다음날/NNG', '단다/EF', '단색/NNG', '단아/XR', '달/NNG', '달/VX', '달마/NNP', '당기/VV', '대/EF', '대구예술대학교/NNP', '대로/NNP', '대신/NNG', '대전/NNG', '대체로/MAG', '대하/VV', '대학/NNG', '대학교/NNG', '대학동/NNP', '대학로/NNP', '대회/NNG', '댁/NNG', '댁/XSN', '더/MAG', '더라/EF', '덕분/NNG', '던/ETM', '던가/EF', '덥/VA', '데/EF', '데/NNB', '데이트/NNG', '도/JX', '도/NNB', '도록/EC', '도서관/NNP', '도와주/VV', '도착/NNG', '독서실/NNP', '돈/NNG', '돌아오/VV', '돕/VV', '동/MM', '동기/NNG', '동기/NNP', '동료/NNG', '동반/NNG', '동사무소/NNG', '동생/NNG', '동안/NNG', '동안/NNP', '동창/NNG', '동창/NNP', '동창회/NNG', '동해/NNP', '돼지/NNP', '되/NNB', '되/VV', '되/XSV', '두/VX', '두산/NNP', '둘/NR', '뒤/NNG', '드라/EF', '드리/VV', '드리/VX', '든/EF', '들/VV', '들/XSN', '들리/VV', '들어오/VV', '등급/NNP', '등록/NNG', '등록/NNP', '등본/NNG', '등산/NNP', '따르/VV', '딸아/NNP', '때/NNG', '때문/NNB', '땜/NNB', '떠나/VV', '떼/VV', '또/MAJ', '똑같/VA', '라/EC', '라/EF', '라고/EC', '라고/EF', '라고/JKQ', '라고/NNP', '라고요/EF', '라구요/EF', '라는/ETM', '라는데/EF', '라운지/NNP', '란다/EF', '랑/JKB', '래/EF', '러/EC', '레브/NNP', '레스토랑/NNP', '려고/EC', '려고/EF', '렴/EF', '로/JKB', '로비/NNG', '록/NNP', '롯데/NNP', '롯데마트/NNP', '롯데백화점/NNP', '롯데호텔/NNP', '를/JKO', '리눅스/NNP', '마다/JX', '마땅/XR', '마로니에/NNP', '마중가/NNP', '마지막/NNG', '마트/NNP', '만/JX', '만/NNB', '만/NR', '만나/VV', '만요/NNP', '많/VA', '많이/MAG', '말/NNG', '말/VX', '말로/NNP', '말씀/NNG', '맑/VA', '맛나/NNP', '망년회/NNG', '맞/VV', '맞추/VV', '매/NNG', '맹장/NNP', '먹/VV', '메가멕스/NA', '메가박스/NNP', '메모/NNG', '메세지/NNG', '메시지/NNP', '며칠/NNG', '면/EC', '면담/NNG', '명/NNB', '명동/NNP', '명보/NNG', '몇/MM', '모네/NNP', '모두/MAG', '모든/MM', '모레/NNG', '모르/VV', '모시/VV', '모이/VV', '모임/NNG', '모임/NNP', '모자/NNP', '목동/NNP', '목요일/NNP', '못하/VX', '무더위/NNG', '무슨/MM', '무엇/NP', '무용/NNP', '문고/NNP', '문화/NNG', '물감/NNP', '물어보/VV', '물통/NNG', '물통이/NNP', '뭐/NNG', '뭐/NP', '뭔/MM', '뭘/IC', '뮤지컬/NNP', '미란/NNP', '미루/VV', '미리/MAG', '미술/NNP', '미연/NNG', '미연이/NNP', '미영/NNP', '미용실/NNP', '미팅/NNG', '미팅/NNP', '미희랑/NA', '민/NNP', '민이/NNP', '민지/NNP', '밀리/NNP', '밀리오레/NNP', '바/NNB', '바꾸/VV', '바뀌/VV', '바르/VA', '바르/VV', '바쁘/VA', '박/NNP', '박은혜/NNP', '밖/NNG', '반/NNG', '반갑/VA', '반갑습니다/NNP', '반바지/NNP', '반상회/NNG', '반팔/NNG', '받/VV', '발표회/NNG', '밤/NNG', '밥/NNG', '방/NNG', '방과/NNG', '방문/NNG', '방학/NNP', '배우/VV', '백화점/NNG', '백화점/NNP', '버/NNP', '번/NNB', '베니건스/NNP', '변경/NNG', '변하/VV', '별/NNG', '별/XSN', '별일/NNG', '병원/NNG', '보/VV', '보/VX', '보기/NNP', '보내/VV', '보름/NNP', '보미/NNP', '보아주/VV', '보영/NNP', '보이/VV', '볼/NNG', '뵈/VV', '부르/VV', '부모/NNG', '부부/NNG', '부부/NNP', '부서/NNG', '부엌/NNG', '부장/NNP', '부탁/NNG', '부터/JX', '분/NNB', '분/XSN', '분과/NNG', '분홍색/NNG', '불란서/NNP', '불러오/VV', '비/NNG', '비/VV', '비우/VV', '비행기/NNG', '비행기/NNP', '빌리/VV', '빠뜨리/VV', '빨래/NNP', '뿐/NNB', '사/VV', '사람/NNG', '사이/NNG', '사장/NNG', '사촌/NNP', '삭제/NNG', '산책/NNG', '살/VV', '삼/NR', '삼봉/NNP', '삼성/NNP', '삼성동/NNP', '삼성역/NNP', '삼촌/NNP', '상/NNG', '상영/NNG', '상영/NNP', '새/MM', '새로/MAG', '새롭/VA', '새벽/NNG', '색/NNG', '색깔/NNG', '생각/NNG', '생신/NNG', '생일/NNG', '생일/NNP', '생일날/NNG', '서/JKB', '서울/NNP', '서재/NNP', '서점/NNP', '선물/NNG', '선물/NNP', '선배/NNG', '선생님/NNP', '선택/NNG', '설/NNB', '설정/NNG', '설정/NNP', '성호/NNP', '세/NNB', '세/VA', '세븐일레븐/NNP', '세종문화회관/NNP', '세차/NNP', '센터/NNP', '소매/NNP', '소연/NNP', '소요/NNG', '소풍/NNG', '소풍/NNP', '속초/NNP', '송년회/NNG', '쇼핑/NNG', '쇼핑/NNP', '수/NNB', '수경/NNG', '수고/NNG', '수련회/NNG', '수산/NNG', '수업/NNG', '수업/NNP', '수요일/NNP', '수정/NNG', '수지/NNP', '수진/NNP', '수학/NNP', '숙제/NNG', '숙제/NNP', '순이/NNP', '쉬/VV', '쉽/VA', '슈렉/NNP', '스케줄/NNP', '스케치북/NNP', '스타일/NNG', '습니까/EF', '습니다/EC', '습니다/EF', '시/EP', '시/NNB', '시/NNG', '시/VA', '시가/NNP', '시각/NNG', '시각/NNP', '시간/NNG', '시간/NNP', '시간표/NNG', '시골/NNG', '시네마/NNP', '시댁/NNP', '시로/NNP', '시야/NNP', '시작/NNG', '시작/NNP', '시장/NNG', '시지/NNP', '시키/VV', '시키/XSV', '시합/NNG', '시험/NNG', '시험/NNP', '식/NNB', '식구/NNG', '식당/NNG', '식당/NNP', '식사/NNG', '식사/NNP', '신라호텔/NNP', '신세계백화점/NNP', '신은정/NNP', '신청/NNG', '신촌/NNP', '심히/MAG', '싶/VX', '쓰/VV', '쓰기/NNP', '씨/NNB', '씨티/NNG', '아/EC', '아/EF', '아/IC', '아/JKV', '아고/NNP', '아니/IC', '아니/VCN', '아니야/NNP', '아니오/IC', '아도/EC', '아라/EF', '아름/NNP', '아마/NNP', '아무/MM', '아무것/NNG', '아무도/NNP', '아무런/MM', '아빠/NNG', '아서/EC', '아야/EC', '아야지/EF', '아요/EF', '아유/IC', '아이/NNG', '아이고/IC', '아즈카반의/NA', '아직/MAG', '아진/NNP', '아침/NNG', '아침/NNP', '아하/NNP', '안/MAG', '안/NNG', '안녕/IC', '안녕/NNP', '안녕하세요/NNP', '안녕히/MAG', '안방/NNG', '안산/NNP', '안양/NNP', '안지/NNP', '않/VX', '알/VV', '알람/NNP', '알리/VV', '알아보/VV', '알아봐야겟어./NA', '압구정/NNP', '았/EP', '았었/EP', '앞/NNG', '애/EF', '애경/NNP', '야/EF', '야/IC', '야/JKV', '야/JX', '야구/NNP', '야외/NNG', '약/MM', '약속/NNG', '약속/NNP', '약수/NNP', '양복/NNP', '양재동/NNP', '얘기/NNG', '어/EC', '어/EF', '어/IC', '어느/MM', '어디/NP', '어딨니./NA', '어딨니?/NA', '어딨어?/NA', '어떤/MM', '어떻/VA', '어라/EF', '어린이날/NNP', '어버이/NNG', '어버이날/NNP', '어서/EC', '어서/EF', '어야/EC', '어언/MAG', '어요/EC', '어요/EF', '어제/MAG', '어제/NNP', '언니/NNG', '언니네/NNP', '언제/MAG', '언제/NP', '얼마/NNG', '얼마나/MAG', '엄마/NNG', '엄마/NNP', '업무/NNG', '없/VA', '없이/MAG', '었/EP', '에/JKB', '에게/JKB', '에다가/JKB', '에서/JKB', '에요/EF', '여기/NP', '여름', '여름/NNG', '여름휴가/NNG', '여행/NNG', '여행사/NNG', '여행사/NNP', '여행지/NNG', '연결/NNG', '연기/NNG', '연기/NNP', '연수/NNG', '연수/NNP', '연체/NNG', '열/VV', '영숙이/NNP', '영어/NNP', '영업/NNG', '영이/NNP', '영지/NNP', '영풍/NNP', '영풍문고/NNP', '영화/NNG', '영화관/NNP', '영희/NNP', '옆/NNG', '예/IC', '예/NNG', '예모임/NNP', '예배/NNP', '예상/NNG', '예약/NNG', '예정/NNG', '오/EF', '오/NNP', '오/VV', '오/VX', '오늘/NNG', '오래/MAG', '오빠/NNG', '오빠/NNP', '오전/NNG', '오전/NNP', '오후/NNG', '오후/NNP', '온도/NNP', '올/MM', '올라가/VV', '옮기/VV', '옷/NNG', '옷차림/NNG', '와/JC', '와/JKB', '완료/NNG', '왜/MAG', '외/NNB', '외식/NNG', '외출/NNG', '요/EF', '요/JX', '요/NNG', '요일/NNP', '우리/NP', '우철/NNP', '운동/NNG', '운동화/NNP', '울리/VV', '원/NNB', '원래/NNG', '원하/VV', '월요일/NNG', '월요일/NNP', '위치/NNG', '위하/VV', '유미/NNP', '윤경/NNP', '윤정/NNP', '윤희/NNP', '으/NNG', '으니까/EC', '으려고/EC', '으로/JKB', '으루/JKB', '으면/EC', '으시/EP', '은/ETM', '은/JX', '은/NNG', '은데/EC', '은데/EF', '은실이/NNP', '은영/NNP', '은정/NNP', '은지/EC', '은행/NNG', '은행/NNP', '을/ETM', '을/JKO', '을게/EF', '을까/EF', '을까요/EF', '을지/EC', '음/ETN', '음/IC', '음/NNG', '음악회/NNG', '응/IC', '의/JKG', '이/JKS', '이/MM', '이/NNP', '이/VCP', '이나/JC', '이나/JX', '이달/NNP', '이라고/JKQ', '이랑/JKB', '이랑/NNP', '이렇/VA', '이리/MAG', '이리/NNP', '이리로/MAG', '이마트/NNP', '이모/NNP', '이번/NNG', '이상/NNP', '이야/JKV', '이야/JX', '이유/NNG', '이제/MAG', '이제/NNG', '이쪽/NP', '이함/NNP', '이후/NNG', '인어/NNP', '인지/NNP', '일/NNB', '일/NNG', '일/NNP', '일/NR', '일가/NNG', '일거/NNG', '일기/NNP', '일어나/VV', '일요일', '일요일/NNG', '일요일/NNP', '일정/NNG', '일정/NNP', '일정/XR', '일정표/NNG', '잃/VV', '입/VV', '입력/NNG', '입력/NNP', '입원/NNG', '있/VV', '있/VX', '잊/VV', '잊어버리/VV', '자/EC', '자/EF', '자/IC', '자/NNB', '자/VV', '자연/NNG', '자외선', '자외선/NNP', '작년/NNG', '잖아/EC', '잖아/EF', '잘/MAG', '잘/VA', '잠깐/NNP', '잠시/MAG', '잠시/NNG', '잡/VV', '잡아줘/NNP', '잡지/NNP', '잡히/VV', '장/NNG', '장/NNP', '장마/NNP', '장소/NNG', '장소/NNP', '장이/NNP', '장지영/NNP', '재/XPN', '재밌/VA', '재생/NNG', '저/MM', '저/NP', '저기/NP', '저녁/NNG', '저녁/NNP', '저렴/XR', '저번/NNG', '저장/NNG', '전/MM', '전/NNG', '전/NNP', '전날/NNG', '전인/NNP', '전하/VV', '전화/NNG', '전화번호/NNG', '점심/NNG', '점심/NNP', '점심때/NNG', '점심시간/NNG', '정/NNP', '정기/NNG', '정도/NNG', '정리/NNG', '정말/MAG', '정민/NNP', '정보/NNG', '정우재/NNP', '정은/NNP', '정이랑/NNP', '정장/NNG', '정하/VV', '정확/XR', '정확히/MAG', '제대로/MAG', '제목/NNG', '제사/NNG', '제일/NNG', '제주/NNP', '제주도/NNP', '제출/NNG', '제품/NNG', '조/NR', '조금/MAG', '조금/NNG', '조은미/NNP', '조정/NNG', '족/NNG', '좀/MAG', '종/NNG', '종로/NNP', '종현/NNP', '좋/VA', '좋은', '죄송/XR', '죄수/NNG', '주', '주/MM', '주/NNB', '주/NNG', '주/NNP', '주/VV', '주/VX', '주간/NNG', '주년/NNB', '주로/MAG', '주말/NNP', '주무/NNG', '주무/NNP', '주민등록/NNP', '주일/NNB', '주일/NNP', '준비/NNG', '준비물/NNG', '중/NNB', '중반/NNG', '중복/NNG', '중순/NNG', '중앙/NNP', '중요/XR', '중학교/NNP', '즐겁/VA', '즘/NNB', '증조할머니/NNG', '증조할아버지/NNG', '지/EC', '지/EF', '지/NNB', '지/VX', '지금/MAG', '지금/NNG', '지나/VV', '지내/VV', '지도/NNP', '지선/NNP', '지수/NNG', '지영/NNP', '직원/NNG', '짐/NNG', '집/NNG', '째/XSN', '쯤/NNB', '차단제/NNP', '참/MAG', '참석/NNG', '찾/VV', '찾아보/VV', '책/NNG', '책가방/NNP', '챙기/VV', '처리/NNG', '천/NNP', '천천히/MAG', '철민/NNP', '철수/NNP', '첫째/NR', '청색/NNG', '청소/NNG', '청소/NNP', '청소년/NNG', '체육/NNG', '체육/NNP', '체크/NNP', '초/NNB', '초등학교/NNP', '초야/NNP', '총/MM', '최고/NNP', '최근/NNG', '최저/NNG', '추가/NNG', '추도/NNP', '추석/NNG', '추석/NNP', '추천/NNG', '축하/NNG', '출력/NNG', '출발/NNG', '출장/NNG', '충전/NNP', '취/NA', '취소/NNG', '취소/NNP', '치과/NNG', '치기/NNG', '친구/NNG', '친구/NNP', '친목/NNG', '친척/NNG', '카페/NNP', '캠프/NNP', '커피숍/NNP', '콘도/NNG', '퀼트를/NA', '큰아버지/NNG', '태/NNP', '테/NNG', '테니스/NNP', '테크노마트/NNP', '토요일', '토요일/NNG', '토요일/NNP', '퇴근/NNG', '퇴원/NNG', '투/NNB', '투어/NNG', '투피스/NNG', '특별/XR', '티에/NNP', '팀/NNG', '파티/NNG', '파티/NNP', '패키지/NNP', '편의점/NNP', '편찮/VA', '편하/VA', '포터/NNP', '표/NNG', '피곤/NNG', '피서/NNG', '필요/NNG', '하/NNG', '하/VV', '하/VX', '하/XSA', '하/XSV', '하고/JKB', '하이/NNP', '학/NNG', '학교', '학교/NNG', '학교/NNP', '학원/NNG', '학원/NNP', '학원가/NNG', '한/MM', '한/NNP', '한양/NNP', '한양대학교/NNP', '한테/JKB', '한화/NNP', '할/NNB', '할거/NNG', '할머니/NNG', '할아버지/NNG', '함께/MAG', '해/NNG', '해달/NNP', '해랑/NNP', '해리/NNP', '해수욕장/NNP', '해조/NNG', '햇빛/NNP', '행사/NNG', '행사/NNP', '헬스/NNG', '현관/NNP', '현대/NNP', '현대백화점/NNP', '현배/NNP', '현재/MAG', '현재/NNG', '혜/NNG', '혜진/NNP', '혹시/MAG', '홈/NNG', '홍/NNP', '화관/NNP', '화요일/NNG', '화요일/NNP', '확실히/MAG', '확인/NNG', '회관/NNG', '회사/NNG', '회식/NNG', '회의/NNG', '회의/NNP', '후/NNG', '후배/NNG', '후에/NNP', '훼/NNG', '휴가/NNG', '휴가/NNP', '휴양림/NNP', '흐/NA', '흐리/VA', '힐튼호텔/NNP'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNoshvPH2Bqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# emd = nn.Embedding(num_embeddings = len(word2index) ,embedding_dim = 128)\n",
        "word_list_te = []\n",
        "for key in data_te:\n",
        "  sentence_list = [i[1] for i in data_te[key]]\n",
        "  for sentence in sentence_list:\n",
        "    index_word = []\n",
        "    if sentence:\n",
        "      o_word = komoran.get_plain_text(sentence)\n",
        "      for word in o_word.split(' '):\n",
        "        if word not in word2index.keys():\n",
        "          index_word.append(word2index['<UKN>'])\n",
        "        else:\n",
        "          index_word.append(word2index[word])\n",
        "    word_list_te.append(index_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P4kYT3709DN",
        "colab_type": "code",
        "outputId": "f783506f-3d10-4420-e91a-1cd96594a38f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(len(word_list_tr))\n",
        "print(len(label_list_tr))\n",
        "print(len(word_list_te))\n",
        "print(len(label_list_te))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5825\n",
            "5825\n",
            "6671\n",
            "6671\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7tpaWeK1CZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list를 torch.tensor로 만드려면 list의 길이가 같아야 함 그래서 0으로 패딩\n",
        "max_len = 50\n",
        "word_list_tr_ = np.array([i + [0] * (max_len - len(i)) for i in word_list_tr])\n",
        "word_list_te_ = np.array([i + [0] * (max_len - len(i)) for i in word_list_te])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wr2ZZOujTpZS",
        "colab_type": "code",
        "outputId": "95e0fc68-7622-463a-feb3-2ccbd9a26511",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        }
      },
      "source": [
        "word_list_tr_[:5]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 746,  738, 1011, 1004,  783,  332,   84,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0],\n",
              "       [ 311,    5, 1011, 1004,  783,  693,    7,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0],\n",
              "       [ 746,  738,  987, 1261, 1078, 1212,  735, 1092,  802,    7,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0],\n",
              "       [ 825,  987,  937, 1261, 1215,  106,   84,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0],\n",
              "       [ 348,  354,  987, 1078,  779,  801, 1092,  802,    7,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrmPgLUAD1zN",
        "colab_type": "code",
        "outputId": "0ddbe675-51ff-4123-a67c-adc57ab4def1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "label_list_tr[:4]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 1, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nga6XZ7KEJqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_tensor_tr = torch.tensor(word_list_tr_)\n",
        "label_tensor_tr = torch.tensor(label_list_tr)\n",
        "word_tensor_te = torch.tensor(word_list_te_)\n",
        "label_tensor_te = torch.tensor(label_list_te)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyAxXepUPJEf",
        "colab_type": "code",
        "outputId": "12bb727a-4be6-4309-8538-9cffda2faec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(word_tensor_tr.size(), label_tensor_tr.size())\n",
        "print(word_tensor_te.size(), label_tensor_te.size())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5825, 50]) torch.Size([5825])\n",
            "torch.Size([6671, 50]) torch.Size([6671])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUjUVnCFQ8gv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 6 번째 과제 , ‘Multi Layer Perceptron 을 활용한 화행 분석 ’ 참조\n",
        "# 8 번째 과제 , ‘Convolution Neural Networks 를 활용한 화행 분석 (2)’ 참조\n",
        "epochs = 100\n",
        "dropout = 0.5\n",
        "learning_rate = 0.001\n",
        "\n",
        "class CNN(torch.nn.Module):\n",
        "  def __init__(self, vocab_size, num_labels):\n",
        "    super(CNN, self).__init__()\n",
        "    self.word_embed = torch.nn.Embedding(num_embeddings=vocab_size, embedding_dim=128, padding_idx=0)\n",
        "    \n",
        "    self.conv1 = nn.Conv1d(in_channels=128, out_channels=32, kernel_size=3, stride=1)\n",
        "    self.conv2 = nn.Conv1d(in_channels=32, out_channels=16, kernel_size=3, stride=1)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.maxp1 = nn.MaxPool1d(3)\n",
        "    self.maxp2 = nn.MaxPool1d(12)\n",
        "    \n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.fc1 = nn.Linear(16 * 3, num_labels, bias=True)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    embedded = self.word_embed(inputs).permute(0, 2, 1)\n",
        "    x = self.maxp1(self.relu(self.conv1(embedded)))\n",
        "    x = self.maxp2(self.relu(self.conv2(x))).squeeze(2)\n",
        "    x = self.dropout(torch.cat((x,x,x), dim = 1))\n",
        "\n",
        "    pred = self.fc1(x)\n",
        "\n",
        "    return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VElOa5ygNmT",
        "colab_type": "code",
        "outputId": "f22d7a9e-b49c-4348-fa09-9624e55250aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "# GPU 가능 여부 및 선택\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# train_tfidf_tensor shape = (발화 수, tfidf_size)\n",
        "model = CNN(vocab_size = len(word2index), num_labels=8)\n",
        "\n",
        "# model을 GPU로 이동\n",
        "model.to(device)"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (word_embed): Embedding(1277, 128, padding_idx=0)\n",
              "  (conv1): Conv1d(128, 32, kernel_size=(3,), stride=(1,))\n",
              "  (conv2): Conv1d(32, 16, kernel_size=(3,), stride=(1,))\n",
              "  (relu): ReLU()\n",
              "  (maxp1): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
              "  (maxp2): MaxPool1d(kernel_size=12, stride=12, padding=0, dilation=1, ceil_mode=False)\n",
              "  (dropout): Dropout(p=0.6, inplace=False)\n",
              "  (fc1): Linear(in_features=48, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9esoWOIgQV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train data를 이용 CNN 모델 학습\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# TensorDataset을 이용하여 Input/output data를 하나로 묶음\n",
        "Train_dataset = torch.utils.data.TensorDataset(word_tensor_tr, label_tensor_tr)\n",
        "Test_dataset = torch.utils.data.TensorDataset(word_tensor_te, label_tensor_te)\n",
        "\n",
        "# DataLoader를 선언하고 batch size 만큼 데이터를 가지고 와서 학습\n",
        "# Shuffle 여부 결정\n",
        "train_DataLoader = torch.utils.data.DataLoader(Train_dataset, shuffle=True, batch_size=4)\n",
        "test_DataLoader = torch.utils.data.DataLoader(Test_dataset, shuffle=False, batch_size=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsSqBQHgVZ-a",
        "colab_type": "code",
        "outputId": "a0c3157b-aacd-4acc-ef9e-58b6426b70f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "model.train(True)\n",
        "model.zero_grad()\n",
        "for epoch in range(epochs):\n",
        "  epoch_loss = 0\n",
        "  for batch in train_DataLoader:\n",
        "    # batch : (tfidf data, label)\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    y_pred = model(batch[0])\n",
        "\n",
        "    loss = criterion(y_pred, batch[1])\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    model.zero_grad()\n",
        "  if (epoch+1) % 10 == 0:\n",
        "    print(epoch, epoch_loss)\n",
        "model.train(False)"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9 705.4591852826998\n",
            "19 642.4179804844316\n",
            "29 683.8232677261985\n",
            "39 622.4573948900797\n",
            "49 698.0531187830784\n",
            "59 774.7222020104527\n",
            "69 949.1826521605253\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (word_embed): Embedding(1277, 128, padding_idx=0)\n",
              "  (conv1): Conv1d(128, 32, kernel_size=(3,), stride=(1,))\n",
              "  (conv2): Conv1d(32, 16, kernel_size=(3,), stride=(1,))\n",
              "  (relu): ReLU()\n",
              "  (maxp1): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
              "  (maxp2): MaxPool1d(kernel_size=12, stride=12, padding=0, dilation=1, ceil_mode=False)\n",
              "  (dropout): Dropout(p=0.6, inplace=False)\n",
              "  (fc1): Linear(in_features=48, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNhCAnO5yuMD",
        "colab_type": "code",
        "outputId": "205e1fcd-61be-49d8-acec-e6240629de8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''\n",
        "# Test model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for images, labels in test_DataLoader:\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "    _, pred = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (pred == labels).sum().item()\n",
        "\n",
        "  print('Test Accuracy of the model on the  : {}'.format(100*correct/total))\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the  : 94.99325438464997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm1Oa9C_4QRY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Test\n",
        "model.eval()\n",
        "pred = None\n",
        "label = None\n",
        "for batch in test_DataLoader:\n",
        "  # batch : [tfidf_data, label]\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  # gradient를 계산하지 않도록 선언\n",
        "  with torch.no_grad():\n",
        "    y_pred = model(batch[0])\n",
        "\n",
        "  if pred is None:\n",
        "    pred = y_pred.detach().cpu().numpy()\n",
        "    label = batch[1].detach().cpu().numpy()\n",
        "  else:\n",
        "    pred = np.append(pred, y_pred.detach().cpu().numpy(), axis=0)\n",
        "    label = np.append(label, batch[1].detach().cpu().numpy(), axis=0)\n",
        "\n",
        "pred = np.argmax(pred, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7GFEEl532Of",
        "colab_type": "code",
        "outputId": "29c0284f-bf95-4971-eeff-8a57735b7e18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if len(label_tensor_te) == len(pred):\n",
        "  print(\"True\")"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xqynv87u4h84",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval(true, pred):\n",
        "    ave = ['macro', 'micro']\n",
        "    precision = []\n",
        "    recall = []\n",
        "    fbeta = []\n",
        "    f1 = []\n",
        "    acc = accuracy_score(true, pred)\n",
        "    for i in ave:\n",
        "        precision.append(precision_score(true, pred, average=i))\n",
        "        recall.append(recall_score(true, pred, average=i))\n",
        "        f1.append(f1_score(true, pred, average=i))\n",
        "    return acc, precision, recall, f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve-Jj7sG4iAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conf_mat = confusion_matrix(label_tensor_te, pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbQ7BTBI4tA2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b8fff084-a27d-43a7-b2c7-8942e593c7b8"
      },
      "source": [
        "evaluation = eval(label_tensor_te, pred)"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2UWNlHU4xu9",
        "colab_type": "code",
        "outputId": "7061e0dc-96d8-4122-9126-c9945bf06ea3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "evaluation"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8506970469195023,\n",
              " [0.7005980489636119, 0.8506970469195023],\n",
              " [0.5932539220143238, 0.8506970469195023],\n",
              " [0.630922640501747, 0.8506970469195023])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq8UAO164zb6",
        "colab_type": "code",
        "outputId": "9c0e740a-1e1f-4ccf-a638-856ae8ea8604",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "save_file_name = '2019711752_윤민형_CNN_EXPERIMENT_3'\n",
        "with open('./'+save_file_name+'.txt', 'w', encoding='utf-8', newline='') as writer_text:\n",
        "    list = ['precision', 'recall', 'f1-score']\n",
        "    writer_text.writelines('epochs : ' + str(epochs) +'\\n' + 'dropout : ' + str(dropout) + '\\n' + 'learning_rate : ' + str(learning_rate) + '\\n\\n')\n",
        "    for idx, k in enumerate(range(len(evaluation[1:]))):\n",
        "        a = np.round(evaluation[k+1][0]*100, 4)\n",
        "        b = np.round(evaluation[k+1][1]*100, 4)\n",
        "        writer_text.writelines('Macro average ' + str(list[idx]) +' : ' + str(a) +'%' + '\\n')\n",
        "        writer_text.writelines('Micro averate ' + str(list[idx]) +' : ' + str(b) +'%'+ '\\n\\n')\n",
        "    #writer_text.close()\n",
        "    print(\"[저장 완료]\")"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[저장 완료]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lKKZojkOMIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}