{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2019711752_윤민형_MLP",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8qzlvX4Kk4G",
        "colab_type": "code",
        "outputId": "414b213c-d1e5-42f2-9020-ce690dfd02b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "!pip install PyKomoran"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting PyKomoran\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/b0/ce6a46f311651ed64c39beb1cfe1c39a9906521139ace45430d08c489b62/PyKomoran-0.1.5-py3-none-any.whl (7.9MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9MB 6.3MB/s \n",
            "\u001b[?25hCollecting py4j==0.10.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/de/2d314a921ef4c20b283e1de94e0780273678caac901564df06b948e4ba9b/py4j-0.10.8.1-py2.py3-none-any.whl (196kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 60.2MB/s \n",
            "\u001b[?25hInstalling collected packages: py4j, PyKomoran\n",
            "Successfully installed PyKomoran-0.1.5 py4j-0.10.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pCFkGalKt-f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "from PyKomoran import *\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, fbeta_score\n",
        "import torch\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQgPipHEKuEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_seed():\n",
        "  random.seed(777)\n",
        "  np.random.seed(777)\n",
        "  torch.manual_seed(777)\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(777)\n",
        "\n",
        "set_seed()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BPcH2TAKuBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_list = ['opening', 'request', 'wh-question', 'yn-question', 'inform', 'affirm', 'ack', 'expressive']\n",
        "label_map = {label: i for i, label in enumerate(label_list)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOmiG_qNKxiL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "komoran = Komoran(\"EXP\")\n",
        "\n",
        "with open('./SpeechAct_tr.json', 'r', encoding='utf-8') as read_file:\n",
        "    data_tr = json.load(read_file)\n",
        "\n",
        "tfidf_word_tr = []\n",
        "tfidf_label_tr = []\n",
        "for key_tr in data_tr:\n",
        "  if data_tr[key_tr] == 0:\n",
        "    continue\n",
        "  for message_tr in range(len(data_tr[key_tr])):\n",
        "    komoran_text_tr = ' '.join(komoran.get_morphes_by_tags(data_tr[key_tr][message_tr][1],\n",
        "                                                        tag_list=['NNP', 'NNG', 'VV']))\n",
        "    tfidf_word_tr.append(komoran_text_tr)\n",
        "    komoran_label_tr = data_tr[key_tr][message_tr][2]\n",
        "    tfidf_label_tr.append(komoran_label_tr)\n",
        "\n",
        "tfidfvect_tr = TfidfVectorizer(token_pattern='(?u)\\\\b\\\\w+\\\\b', stop_words=None)\n",
        "tfidfvect_tr.fit_transform(tfidf_word_tr)\n",
        "\n",
        "train_label_list = []\n",
        "for i in tfidf_label_tr:\n",
        "  if i in label_map.keys():\n",
        "    train_label_list.append(label_map[i])\n",
        "train_tfidf_list = tfidfvect_tr.transform(tfidf_word_tr).toarray().tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPH_KAmhK3Ps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('./SpeechAct_te.json', 'r', encoding='utf-8') as read_file:\n",
        "    data_te = json.load(read_file)\n",
        "\n",
        "tfidf_word_te = []\n",
        "tfidf_label_te = []\n",
        "for key_te in data_te:\n",
        "  if data_te[key_te] == 0:\n",
        "    continue\n",
        "  for message_te in range(len(data_te[key_te])):\n",
        "    komoran_text_te = ' '.join(komoran.get_morphes_by_tags(data_te[key_te][message_te][1],\n",
        "                                                        tag_list=['NNP', 'NNG', 'VV']))\n",
        "    tfidf_word_te.append(komoran_text_te)\n",
        "    komoran_label_te = data_te[key_te][message_te][2]\n",
        "    tfidf_label_te.append(komoran_label_te)\n",
        "\n",
        "tfidfvect_te = TfidfVectorizer(token_pattern='(?u)\\\\b\\\\w+\\\\b', stop_words=None)\n",
        "tfidfvect_te.fit_transform(tfidf_word_tr)\n",
        "\n",
        "test_label_list = []\n",
        "for i in tfidf_label_te:\n",
        "  if i in label_map.keys():\n",
        "    test_label_list.append(label_map[i])\n",
        "test_tfidf_list = tfidfvect_te.transform(tfidf_word_te).toarray().tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1KaQbwhMf8l",
        "colab_type": "code",
        "outputId": "ad9607e2-5a15-478c-b785-d189f1adf714",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(len(train_tfidf_list), len(train_label_list))\n",
        "print(len(test_tfidf_list), len(test_label_list))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5825 5825\n",
            "6671 6671\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZbUKmPQYQiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tfidf_tensor = torch.tensor(train_tfidf_list)\n",
        "train_label_tensor = torch.tensor(train_label_list)\n",
        "test_tfidf_tensor = torch.tensor(test_tfidf_list)\n",
        "test_label_tensor = torch.tensor(test_label_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8D9wDoqYUx6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "a6724b44-3845-4559-ed8a-7981bfb7c3a1"
      },
      "source": [
        "print(train_tfidf_tensor.shape)\n",
        "print(train_label_tensor.shape)\n",
        "print(test_tfidf_tensor.shape)\n",
        "print(test_label_tensor.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5825, 743])\n",
            "torch.Size([5825])\n",
            "torch.Size([6671, 743])\n",
            "torch.Size([6671])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASb0q4gxY4F2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Perceptron(torch.nn.Module):\n",
        "  def __init__(self, tfidf_size, num_label):\n",
        "    super(Perceptron, self).__init__()\n",
        "    self.linear = torch.nn.Linear(tfidf_size, num_label)\n",
        "\n",
        "  def forward(self, tfidf_input):\n",
        "    y_pred = self.linear(tfidf_input)\n",
        "\n",
        "    return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBFPfYIEbu0A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "2a4d026c-d778-40e4-ee00-75350c6d60fa"
      },
      "source": [
        "# GPU 가능 여부 및 선택\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# train_tfidf_tensor shape = (발화 수, tfidf_size)\n",
        "model = Perceptron(tfidf_size = train_tfidf_tensor.shape[1], num_label=len(label_list))\n",
        "\n",
        "# model을 GPU로 이동\n",
        "model.to(device)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Perceptron(\n",
              "  (linear): Linear(in_features=743, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evLGqiUycYE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzG1atWbc-_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TensorDataset을 이용하여 Input/output data를 하나로 묶음\n",
        "Train_dataset = torch.utils.data.TensorDataset(train_tfidf_tensor, train_label_tensor)\n",
        "Test_dataset = torch.utils.data.TensorDataset(test_tfidf_tensor, test_label_tensor)\n",
        "\n",
        "# DataLoader를 선언하고 batch size 만큼 데이터를 가지고 와서 학습\n",
        "# Shuffle 여부 결정\n",
        "train_DataLoader = torch.utils.data.DataLoader(Train_dataset, shuffle=True, batch_size=4)\n",
        "test_DataLoader = torch.utils.data.DataLoader(Test_dataset, shuffle=False, batch_size=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlQfQ8ywdzWv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 950
        },
        "outputId": "9e4801e8-176e-45da-b6d2-48e3f1400b36"
      },
      "source": [
        "# Train\n",
        "model.train(True)\n",
        "model.zero_grad()\n",
        "for epoch in range(500):\n",
        "  epoch_loss = 0\n",
        "  for batch in train_DataLoader:\n",
        "    # batch : (tfidf data, label)\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    y_pred = model(batch[0])\n",
        "\n",
        "    loss = criterion(y_pred, batch[1])\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    model.zero_grad()\n",
        "  if (epoch+1) % 10 == 0:\n",
        "    print(epoch, epoch_loss)\n",
        "model.train(False)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9 1103.7283244729042\n",
            "19 958.6925388872623\n",
            "29 903.0958309993148\n",
            "39 872.0457537174225\n",
            "49 851.3249836042523\n",
            "59 837.1129299998283\n",
            "69 826.3753804266453\n",
            "79 818.3898889869452\n",
            "89 812.0431623831391\n",
            "99 805.9857422597706\n",
            "109 802.1300911083817\n",
            "119 797.4468386806548\n",
            "129 795.1456507565454\n",
            "139 792.2450955696404\n",
            "149 788.5901269316673\n",
            "159 786.6082487776875\n",
            "169 785.295797586441\n",
            "179 782.9158060178161\n",
            "189 781.4034805325791\n",
            "199 780.4541671387851\n",
            "209 779.0619646348059\n",
            "219 777.9139478579164\n",
            "229 776.5090017709881\n",
            "239 776.1416970267892\n",
            "249 775.208323545754\n",
            "259 774.3706013076007\n",
            "269 773.6660101357847\n",
            "279 772.7106293775141\n",
            "289 772.2353050597012\n",
            "299 771.6814183667302\n",
            "309 771.2304613254964\n",
            "319 770.4629209861159\n",
            "329 770.2456400748342\n",
            "339 769.7179885618389\n",
            "349 770.1528772823513\n",
            "359 769.3615378402174\n",
            "369 768.7022183034569\n",
            "379 768.3300602324307\n",
            "389 768.3663168661296\n",
            "399 767.8026814833283\n",
            "409 767.5243470594287\n",
            "419 767.3848301488906\n",
            "429 766.9996184678748\n",
            "439 766.8820808157325\n",
            "449 766.8889205269516\n",
            "459 766.5046111643314\n",
            "469 766.3932860544883\n",
            "479 766.0226956550032\n",
            "489 765.8887611040846\n",
            "499 765.8651599660516\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Perceptron(\n",
              "  (linear): Linear(in_features=743, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MepgXxlLeteo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test\n",
        "model.eval()\n",
        "pred = None\n",
        "label = None\n",
        "for batch in test_DataLoader:\n",
        "  # batch : [tfidf_data, label]\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  # gradient를 계산하지 않도록 선언\n",
        "  with torch.no_grad():\n",
        "    y_pred = model(batch[0])\n",
        "\n",
        "  if pred is None:\n",
        "    pred = y_pred.detach().cpu().numpy()\n",
        "    label = batch[1].detach().cpu().numpy()\n",
        "  else:\n",
        "    pred = np.append(pred, y_pred.detach().cpu().numpy(), axis=0)\n",
        "    label = np.append(label, batch[1].detach().cpu().numpy(), axis=0)\n",
        "\n",
        "pred = np.argmax(pred, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5rvyWYdhXME",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e2be4fdc-0ffb-47a4-ff83-19091589892c"
      },
      "source": [
        "if len(test_label_tensor) == len(pred):\n",
        "  print(\"True\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnOaZ6AZhvcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval(true, pred):\n",
        "    ave = ['macro', 'micro']\n",
        "    precision = []\n",
        "    recall = []\n",
        "    fbeta = []\n",
        "    f1 = []\n",
        "    acc = accuracy_score(true, pred)\n",
        "    for i in ave:\n",
        "        precision.append(precision_score(true, pred, average=i))\n",
        "        recall.append(recall_score(true, pred, average=i))\n",
        "        f1.append(f1_score(true, pred, average=i))\n",
        "    return acc, precision, recall, f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEwTkfnsh5DP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conf_mat = confusion_matrix(test_label_tensor, pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_CoXpdkijRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluation = eval(test_label_tensor, pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJFW52enikfp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "f60160e7-1f0c-4a3d-80d2-46692ea23d9f"
      },
      "source": [
        "evaluation"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7949332933593164,\n",
              " [0.7436745887350917, 0.7949332933593164],\n",
              " [0.732319876517449, 0.7949332933593164],\n",
              " [0.7307183367455284, 0.7949332933593164])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgcc-jEhiuLE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e169c97f-615f-4ddc-9cc0-b0d8040ec6aa"
      },
      "source": [
        "save_file_name = '2019711752_윤민형_MLP'\n",
        "with open('./'+save_file_name+'.txt', 'w', encoding='utf-8', newline='') as writer_text:\n",
        "    list = ['precision', 'recall', 'f1-score']\n",
        "    for idx, k in enumerate(range(len(evaluation[1:]))):\n",
        "        writer_text.writelines('Macro average ' + str(list[idx]) +' : ' \n",
        "                               + str(evaluation[k+1][0]*100) +'%' + '\\n')\n",
        "        writer_text.writelines('Micro averate ' + str(list[idx]) +' : ' \n",
        "                               + str(evaluation[k+1][1]*100) +'%'+ '\\n\\n')\n",
        "    #writer_text.close()\n",
        "    print(\"[저장 완료]\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[저장 완료]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svo80l1li2ej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}